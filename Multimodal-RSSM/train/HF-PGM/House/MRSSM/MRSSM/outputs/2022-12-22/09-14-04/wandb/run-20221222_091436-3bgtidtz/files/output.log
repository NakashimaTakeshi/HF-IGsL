using cuda:1
Initialize training environment and experience replay memory
load dataset from /root/HSR/Multimodal-RSSM/train/HF-PGM/House/MRSSM/MRSSM/../../../../../dataset/HF-PGM/MobileRobot_with_Image_Pose/MobileRobotImage_20221127/train
find 10 npy files!
set color augment params
calc pca from torch.Size([287, 3, 258, 258]) data
load dataset from /root/HSR/Multimodal-RSSM/train/HF-PGM/House/MRSSM/MRSSM/../../../../../dataset/HF-PGM/MobileRobot_with_Image_Pose/MobileRobotImage_20221127/validation
find 3 npy files!
set color augment params
calc pca from torch.Size([87, 3, 258, 258]) data
Initialise model parameters randomly
RSSM
load dataset: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.03it/s]
load dataset: 100%|████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.89it/s]
train:   0%|                                                                                | 0/8000 [00:00<?, ?it/s]/root/HSR/Multimodal-RSSM/train/HF-PGM/House/MRSSM/MRSSM/../../../../../algos/MRSSM/base/base.py:422: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  nn.utils.clip_grad_norm_(self.param_list, self.cfg.rssm.grad_clip_norm, norm_type=2)























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































train: 100%|███████████████████████████████████████████████████████████████████| 8000/8000 [1:44:40<00:00,  1.27it/s]