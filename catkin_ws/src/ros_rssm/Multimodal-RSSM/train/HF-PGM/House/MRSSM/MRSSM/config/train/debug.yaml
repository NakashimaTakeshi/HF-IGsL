# train:
train_data_path: 
# - ../../../../../dataset/COBOTTA/SingleHoleDrilling/dataset/train
- /home/docker/sharespace/dataset/COBOTTA/SingleHoleDrilling/dataset/train
validation_data_path:
# - ../../../../../dataset/COBOTTA/SingleHoleDrilling/dataset/validation
- /home/docker/sharespace/dataset/COBOTTA/SingleHoleDrilling/dataset/validation

# Original implementation has an unlimited buffer size, but 1 million is the max experience collected anyway
experience_size: 500_000

train_iteration: 1_00
checkpoint_interval: 100
validation_interval: 10
test: False
test_interval: 
test_episodes: 

batch_size: 50                      # default: 50
chunk_size: 50                      # default: 50

action_noise: 0.3                   # default: 0.3

augmentation:
  n_crop: 9
  dh_base: 1
  dw_base: 1
  noise_scales: [0.]
  pca_scales: [0.]

use_amp: True

model_path: 

# setting example
# pretrained_model:
#   model_name:
#     model_path: results/experiment_name/date/run_id/models_itr.pth
#     observations:
#       image_horizon:
#         load_encoder: True
#         load_decoder: True
#       sound:
#         load_encoder: True
#         load_decoder: True
pretrained_model:
  model1:
    model_path: results/image_horizon-seed_0/2022-11-29/run_0/models_2000.pth
    observations:
      image_horizon:
        load_encoder: True
        load_decoder: True
  model2:
    model_path: results/sound-seed_0/2022-11-29/run_0/models_2000.pth
    observations:
      sound:
        load_encoder: True
        load_decoder: True